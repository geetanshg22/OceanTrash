# -*- coding: utf-8 -*-
"""Copy of Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18NYZLQsDeRx5ATzPZ-CEphAawMwu4G80
"""



#from google.colab import drive
#drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data = pd.read_csv("Data.csv")

data.columns

data.head()

data = data.drop(['X','Y','OBJECTID','SEA_STATE_','SOURCE','INFO','CD4'],axis=1)

data.groupby('DATE')
data.head()

data = data.groupby('DATE').agg({'LATITUDE':'mean','LONGITUDE':'mean','CD1____KM_':'sum','CD2____KM_':'sum','CD3____KM_':'sum','CD4____KM_':'sum'})

data = data.reset_index()

data['DATE'] = pd.to_datetime(data['DATE'])

data=data.sort_values("DATE")
data.head()

data['sum'] = data['CD1____KM_']+data['CD2____KM_']+data['CD3____KM_']+data['CD4____KM_']
data.head()

data1 = data.drop(['DATE','CD1____KM_',	'CD2____KM_',	'CD3____KM_',	'CD4____KM_'],axis=1)

data1.head()
data1.describe()

from sklearn.cluster import KMeans

X = data1.iloc[:,0:2].values

#data1.head()
#X.head()

kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=1000, n_init=10, random_state=0,copy_x=True)
pred_y = kmeans.fit_predict(X)

plt.scatter(X[:,0], X[:,1],c = pred_y,s=50,cmap = 'viridis')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')
plt.show()

centroid = kmeans.cluster_centers_
print(centroid)

# wcss = []
# for i in range(1, 11):
#     kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
#     kmeans.fit(X)
#     wcss.append(kmeans.inertia_)
# plt.plot(range(1, 11), wcss)
# plt.title('The Elbow Method')
# plt.xlabel('Number of clusters')
# plt.ylabel('WCSS')
# plt.show()

d = pd.read_csv('OSMC.csv')

d.head()

d.describe()
d = d.drop(['platform_type','sst','slp','lon360'],axis=1)

d.head()

d = d.drop([0],axis=0)
d.head()

d.head()

d = d.dropna(axis=0)
d.head()
d.describe()

d1 = d.groupby('platform_code').agg(['first', 'last']).stack().reset_index('platform_code')

print(d1[d1['platform_code']==1101520.0])

d1 = d1.drop('time',axis=1)

d2 = d1.loc['first',:]
d3 = d1.loc['last',:]

d2.count()

d2 = d2.drop(['platform_code'],axis=1)
d3 = d3.drop(['platform_code'],axis=1)

d2.head()
d3.head()

d2 = d2.reset_index(drop=True)
d2.head()

d3 = d3.reset_index(drop=True)
d3.head()

y = kmeans.predict(d3.iloc[:,0:2].values)

print(kmeans.cluster_centers_)

y.shape

df = pd.DataFrame({'class': y})
df.count()

d2 = d2.merge(df,left_index = True, right_index = True)
d2.head()

from sklearn.model_selection import train_test_split
X_1 = d2.iloc[:,0:2].values
y_1 = d2.iloc[:,2].values

x_train,x_test,y_train,y_test = train_test_split(X_1,y_1,test_size = 0.3,random_state=0)





from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(criterion='entropy')
classifier.fit(x_train,y_train)

from sklearn.externals import joblib
joblib.dump(classifier, 'model.pkl')
print("Model dumped!")

#predictions = classifier.predict(x_test)
#
#from sklearn.metrics import accuracy_score
#acc= accuracy_score(y_test,predictions)
#print(acc)
#
#from sklearn.ensemble import RandomForestClassifier
#classifier = RandomForestClassifier(n_estimators= 10,criterion='entropy')
#classifier.fit(x_train,y_train)
#predictions = classifier.predict(x_test)
#
#from sklearn.metrics import accuracy_score
#acc= accuracy_score(y_test,predictions)
#print(acc)

#22.820744,69.125977
#30.7,76.5
#-20.105468,127.617188
#21.109100,70.795898
#
#y1 = classifier.predict([[21.1,70.795]])



#if(y1==0):
#  print("Saint Helena--Lower Atlantic Ocean")
#if(y1==1):
#  print("USA,Hawaii--Atlantic Ocean--Great Pacific Garbage Patch")
#if(y1==2):
#  print("Lori-East Timor--Between Indian and Pacific Ocean")
#if(y1==3):
#  print("Portugal,Sul--Upper Atlantic Ocean")
#if(y1==4):
#  print("Chile--Lower Pacific Ocean")

